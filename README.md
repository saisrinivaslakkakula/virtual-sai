# ğŸ§  Virtual Sai â€” Your AI-Powered Career Assistant

Virtual Sai is a private, local-first AI assistant that answers questions about Sai Srinivas' work experience, based on resumes and journals. It's built using **LlamaIndex**, **local LLMs** (via Ollama), and **Streamlit** for the UI.

---

## ğŸš€ Features

-   ğŸ¤– Ask career-related questions to Virtual Sai
-   ğŸ§  Powered by a custom Retrieval-Augmented Generation (RAG) engine
-   ğŸ’¬ Answers in **first-person** or **third-person** tone
-   ğŸ“ Upload documents to update Virtual Saiâ€™s knowledge
-   ğŸ›¡ï¸ Private, offline-friendly â€” runs entirely on your machine

---

## ğŸ§° Tech Stack

-   [Streamlit](https://streamlit.io/) â€” for the UI
-   [LlamaIndex](https://www.llamaindex.ai/) â€” for document indexing + RAG
-   [Ollama](https://ollama.com) â€” for local language models (Mistral, Phi, etc.)
-   [Sentence Transformers](https://www.sbert.net/) â€” for document embeddings

---

## ğŸ“¦ Installation (Local Setup)

> âš ï¸ Recommended: MacBook with at least 16GB RAM

### 1. Clone the repo

```bash
git clone https://github.com/your-username/virtual-sai.git
cd virtual-sai
```

### ğŸ”¹ Step 2: Install Ollama (for Local LLM)

Go to: https://ollama.com/download
Download and install Ollama for your operating system (macOS recommended).

Then, in a terminal:

```
ollama run phi
```

### ğŸ”¹ Step 3: Set Up Python Virtual Environment

```
python3 -m venv venv
source venv/bin/activate
```

Then install all required packages:

```
pip install --upgrade pip
pip install -r requirements.txt
```

### ğŸ”¹ Step 4: Run the App

```
streamlit run app.py
```
